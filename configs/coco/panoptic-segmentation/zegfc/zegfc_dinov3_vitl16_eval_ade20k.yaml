_BASE_: ../maskformer2_R50_bs16_50ep.yaml
MODEL:
  META_ARCHITECTURE: "FCCLIP"
  SEM_SEG_HEAD:
    NAME: "FCCLIPHead"
    IN_FEATURES: ["res4"]
    DEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES: ["res4"]
    DEFORMABLE_TRANSFORMER_ENCODER_OUT_FEATURES: 1
    COMMON_STRIDE: 16
    TRANSFORMER_ENC_LAYERS: 0
  # backbone part.
  BACKBONE:
    NAME: "DINOv3"
  WEIGHTS: ""
  PIXEL_MEAN: [122.7709383, 116.7460125, 104.09373615]
  PIXEL_STD: [68.5005327, 66.6321579, 70.32316305]
  ZEG_FC:
    USE_RELATIONSHIP_DESCRIPTOR: True
    TEXT_ATTN: True
    TEXT_ATTN_CLS: True
    MEM_ATTN_MASK: False
  FC_CLIP:
    DINOV3_TOKENIZER_PATH: "https://dl.fbaipublicfiles.com/dinov3/thirdparty/bpe_simple_vocab_16e6.txt.gz"
    DINOV3_BACKBONE_PATH: "models/dinov3_vitl16.pth"
    DINOV3_ADAPTER_PATH: "models/dinov3_text_adapter.pth"
    EMBED_DIM: 2048
    GEOMETRIC_ENSEMBLE_ALPHA: 0.4
    GEOMETRIC_ENSEMBLE_BETA: 0.8
  MASK_FORMER:
    TRANSFORMER_DECODER_NAME: "MultiScaleExtendedMaskedTransformerDecoder"
    NUM_OBJECT_QUERIES: 250
    TEST:
      SEMANTIC_ON: True
      INSTANCE_ON: True
      PANOPTIC_ON: True
      OBJECT_MASK_THRESHOLD: 0.0

DATASETS:
  TRAIN: ("openvocab_coco_2017_train_panoptic_with_sem_seg",)
  TEST: ("openvocab_ade20k_panoptic_val_with_seen_coco",)
